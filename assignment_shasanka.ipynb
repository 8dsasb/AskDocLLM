{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41be0a28-c657-42f1-980f-562b9730f03c",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03f366a-8e8b-45b2-b4d7-5b763fc0a294",
   "metadata": {},
   "source": [
    "# Fine Tuning a Language Learning Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0a9f42-add5-44a0-a778-7abd2a5eeeb8",
   "metadata": {},
   "source": [
    "### 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab1743-b9ec-47bc-a519-5149e7518105",
   "metadata": {},
   "source": [
    "This project aims to fine tune a Language Learning Model (LLM) with data scraped from the AskDocs subreddit so as to make it behave like a doctor responding to medical queries. To achieve this, first, posts and comments from the AskDocs are to be pulled. The pulled data are then cleaned and standardized for the purpose of fine tuning. Then, a few potential LLM candidates are selected and benchmarked using Ollama, and then the appropriate model is selected for fine tuning. Once, fine tuned, the model is then tested and benchmarked again and the metrics are compared with the original model to evaluate its performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621e6d5e-f901-4da9-b52e-aa683840b680",
   "metadata": {},
   "source": [
    "### 2. Project Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb47fbea-9b52-4c0d-ad38-ee6ffe770785",
   "metadata": {},
   "source": [
    "For the purpose of our project, we will be making use of a number of libraries in python. The libraries to be used have been listed below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfffbfae-115a-4b87-b269-8643c598a6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import praw\n",
    "import html\n",
    "import ast\n",
    "import os\n",
    "import re\n",
    "import ftfy\n",
    "from markdown_it import MarkdownIt\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cda34cfe-98c1-4869-8dc2-7f36113ca07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = \"Doc\"\n",
    "posts_data = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57bae7d-547c-48e6-980d-7627bcec5e4b",
   "metadata": {},
   "source": [
    "With the help of reddit praw library, the posts and comments from the AskDocs subreddit will be scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44c03b42-f495-48f7-82bb-2c4a2b16f48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = praw.Reddit(\n",
    "    client_id = \"Wyzdr8dkNuFVp0_EwSMuoA\",\n",
    "    client_secret = \"f0uBJYRmNyb_ENBm4ACOolUlZV44Zg\",\n",
    "    user_agent = user_agent\n",
    ")\n",
    "subreddit = rd.subreddit('AskDocs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7a2565-4478-425a-8c6c-a4f79bfd0685",
   "metadata": {},
   "source": [
    "The provided Python function \"scrape_data\" automates the collection of data from a subreddit on Reddit. Users can specify the sorting type of posts (\"hot\" or \"top\") and limit the number of posts to process. For each post, it extracts various details such as the post's ID, title, text content, author, score, number of comments, creation time, and any flair associated with the post. The function also collects data from the top comments, filtering out those made by moderators or automated systems, and captures details like the comment's ID, body, author, score, and more. Data is periodically saved to CSV files every 100 posts to prevent data loss and finally saves all collected data into a CSV file named according to the sort type. Error handling is incorporated to save progress in case of exceptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37d77a48-bb86-4fa8-88ba-27576105a70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data(sort_type='hot', limit=1000, top_comments=10):\n",
    "    try:\n",
    "        if sort_type not in ['hot', 'top']:\n",
    "            raise ValueError(\"sort_type must be 'hot' or 'top'\")\n",
    "\n",
    "        posts_sort = subreddit.top(limit=limit) if sort_type == 'top' else subreddit.hot(limit=limit)\n",
    "\n",
    "        for index, post in enumerate(posts_sort):\n",
    "            if index % 10 == 0:\n",
    "                print(f\"Accessed {index} posts\")\n",
    "\n",
    "            post_data = {\n",
    "                'id': post.id,\n",
    "                'title': post.title,\n",
    "                'selftext': post.selftext,\n",
    "                'author': post.author.name if post.author else None,\n",
    "                'score': post.score,\n",
    "                'num_comments': post.num_comments,\n",
    "                'created_utc': post.created_utc,\n",
    "                'flair': post.link_flair_text\n",
    "            }\n",
    "\n",
    "            comments_data = []\n",
    "\n",
    "            post.comments.replace_more(limit=0)\n",
    "            comments = sorted([comment for comment in post.comments.list() if comment.author and not comment.author.name.startswith(('AutoModerator', 'AskDocs-ModTeam'))], key=lambda x: x.score, reverse=True)[:top_comments]\n",
    "\n",
    "            for comment in comments:\n",
    "                comment_data = {\n",
    "                    'id': comment.id,\n",
    "                    'body': comment.body,\n",
    "                    'author': comment.author.name if comment.author else None,\n",
    "                    'score': comment.score,\n",
    "                    'parent_id': comment.parent_id,\n",
    "                    'created_utc': comment.created_utc,\n",
    "                    'is_submitter': comment.is_submitter,\n",
    "                    'author_flair': comment.author_flair_text if comment.author_flair_text else None\n",
    "                }\n",
    "                comments_data.append(comment_data)\n",
    "\n",
    "            post_data['comments'] = comments_data\n",
    "            posts_data.append(post_data)\n",
    "\n",
    "            if index % 100 == 0 and index != 0:\n",
    "                initial_df = pd.DataFrame(posts_data)\n",
    "                initial_df.to_csv(f'reddit_data_{index}.csv', index=False)\n",
    "                print(f\"Data saved at {index} posts\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        initial_df = pd.DataFrame(posts_data)\n",
    "        initial_df.to_csv('reddit_data_error_save.csv', index=False)\n",
    "        raise\n",
    "\n",
    "    posts_df = pd.DataFrame(posts_data)\n",
    "    posts_df.to_csv(f'ScrapeAskDoc_{sort_type}data.csv', index=False)\n",
    "    print(\"Successfully scraped the data\")\n",
    "    return posts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6f9f39-7405-46ec-8e81-d62175d7c390",
   "metadata": {},
   "source": [
    "Scraping the top posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "efcd8209-1403-49ce-b0f1-adc182514018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessed 0 posts\n",
      "Accessed 10 posts\n",
      "Accessed 20 posts\n",
      "Accessed 30 posts\n",
      "Accessed 40 posts\n",
      "Accessed 50 posts\n",
      "Accessed 60 posts\n",
      "Accessed 70 posts\n",
      "Accessed 80 posts\n",
      "Accessed 90 posts\n",
      "Accessed 100 posts\n",
      "Data saved at 100 posts\n",
      "Accessed 110 posts\n",
      "Accessed 120 posts\n",
      "Accessed 130 posts\n",
      "Accessed 140 posts\n",
      "Accessed 150 posts\n",
      "Accessed 160 posts\n",
      "Accessed 170 posts\n",
      "Accessed 180 posts\n",
      "Accessed 190 posts\n",
      "Accessed 200 posts\n",
      "Data saved at 200 posts\n",
      "Accessed 210 posts\n",
      "Accessed 220 posts\n",
      "Accessed 230 posts\n",
      "Accessed 240 posts\n",
      "Accessed 250 posts\n",
      "Accessed 260 posts\n",
      "Accessed 270 posts\n",
      "Accessed 280 posts\n",
      "Accessed 290 posts\n",
      "Accessed 300 posts\n",
      "Data saved at 300 posts\n",
      "Accessed 310 posts\n",
      "Accessed 320 posts\n",
      "Accessed 330 posts\n",
      "Accessed 340 posts\n",
      "Accessed 350 posts\n",
      "Accessed 360 posts\n",
      "Accessed 370 posts\n",
      "Accessed 380 posts\n",
      "Accessed 390 posts\n",
      "Accessed 400 posts\n",
      "Data saved at 400 posts\n",
      "Accessed 410 posts\n",
      "Accessed 420 posts\n",
      "Accessed 430 posts\n",
      "Accessed 440 posts\n",
      "Accessed 450 posts\n",
      "Accessed 460 posts\n",
      "Accessed 470 posts\n",
      "Accessed 480 posts\n",
      "Accessed 490 posts\n",
      "Accessed 500 posts\n",
      "Data saved at 500 posts\n",
      "Accessed 510 posts\n",
      "Accessed 520 posts\n",
      "Accessed 530 posts\n",
      "Accessed 540 posts\n",
      "Accessed 550 posts\n",
      "Accessed 560 posts\n",
      "Accessed 570 posts\n",
      "Accessed 580 posts\n",
      "Accessed 590 posts\n",
      "Accessed 600 posts\n",
      "Data saved at 600 posts\n",
      "Accessed 610 posts\n",
      "Accessed 620 posts\n",
      "Accessed 630 posts\n",
      "Accessed 640 posts\n",
      "Accessed 650 posts\n",
      "Accessed 660 posts\n",
      "Accessed 670 posts\n",
      "Accessed 680 posts\n",
      "Accessed 690 posts\n",
      "Accessed 700 posts\n",
      "Data saved at 700 posts\n",
      "Accessed 710 posts\n",
      "Accessed 720 posts\n",
      "Accessed 730 posts\n",
      "Accessed 740 posts\n",
      "Accessed 750 posts\n",
      "Accessed 760 posts\n",
      "Accessed 770 posts\n",
      "Accessed 780 posts\n",
      "Accessed 790 posts\n",
      "Accessed 800 posts\n",
      "Data saved at 800 posts\n",
      "Accessed 810 posts\n",
      "Accessed 820 posts\n",
      "Accessed 830 posts\n",
      "Accessed 840 posts\n",
      "Accessed 850 posts\n",
      "Accessed 860 posts\n",
      "Accessed 870 posts\n",
      "Accessed 880 posts\n",
      "Accessed 890 posts\n",
      "Accessed 900 posts\n",
      "Data saved at 900 posts\n",
      "Accessed 910 posts\n",
      "Accessed 920 posts\n",
      "Accessed 930 posts\n",
      "Accessed 940 posts\n",
      "Accessed 950 posts\n",
      "Accessed 960 posts\n",
      "Accessed 970 posts\n",
      "Accessed 980 posts\n",
      "Accessed 990 posts\n",
      "Successfully scraped the data\n"
     ]
    }
   ],
   "source": [
    "top_posts = scrape_data(\"top\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abb3cc4-101f-476e-9726-d01b6a06d5d6",
   "metadata": {},
   "source": [
    "Scraping the hot posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dc79f418-8e91-4d06-bca0-dbd028b4b2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessed 0 posts\n",
      "Accessed 10 posts\n",
      "Accessed 20 posts\n",
      "Accessed 30 posts\n",
      "Accessed 40 posts\n",
      "Accessed 50 posts\n",
      "Accessed 60 posts\n",
      "Accessed 70 posts\n",
      "Accessed 80 posts\n",
      "Accessed 90 posts\n",
      "Accessed 100 posts\n",
      "Data saved at 100 posts\n",
      "Accessed 110 posts\n",
      "Accessed 120 posts\n",
      "Accessed 130 posts\n",
      "Accessed 140 posts\n",
      "Accessed 150 posts\n",
      "Accessed 160 posts\n",
      "Accessed 170 posts\n",
      "Accessed 180 posts\n",
      "Accessed 190 posts\n",
      "Accessed 200 posts\n",
      "Data saved at 200 posts\n",
      "Accessed 210 posts\n",
      "Accessed 220 posts\n",
      "Accessed 230 posts\n",
      "Accessed 240 posts\n",
      "Accessed 250 posts\n",
      "Accessed 260 posts\n",
      "Accessed 270 posts\n",
      "Accessed 280 posts\n",
      "Accessed 290 posts\n",
      "Accessed 300 posts\n",
      "Data saved at 300 posts\n",
      "Accessed 310 posts\n",
      "Accessed 320 posts\n",
      "Accessed 330 posts\n",
      "Accessed 340 posts\n",
      "Accessed 350 posts\n",
      "Accessed 360 posts\n",
      "Accessed 370 posts\n",
      "Accessed 380 posts\n",
      "Accessed 390 posts\n",
      "Accessed 400 posts\n",
      "Data saved at 400 posts\n",
      "Accessed 410 posts\n",
      "Accessed 420 posts\n",
      "Accessed 430 posts\n",
      "Accessed 440 posts\n",
      "Accessed 450 posts\n",
      "Accessed 460 posts\n",
      "Accessed 470 posts\n",
      "Accessed 480 posts\n",
      "Accessed 490 posts\n",
      "Accessed 500 posts\n",
      "Data saved at 500 posts\n",
      "Accessed 510 posts\n",
      "Accessed 520 posts\n",
      "Accessed 530 posts\n",
      "Accessed 540 posts\n",
      "Accessed 550 posts\n",
      "Accessed 560 posts\n",
      "Accessed 570 posts\n",
      "Accessed 580 posts\n",
      "Accessed 590 posts\n",
      "Accessed 600 posts\n",
      "Data saved at 600 posts\n",
      "Accessed 610 posts\n",
      "Accessed 620 posts\n",
      "Accessed 630 posts\n",
      "Accessed 640 posts\n",
      "Accessed 650 posts\n",
      "Accessed 660 posts\n",
      "Accessed 670 posts\n",
      "Accessed 680 posts\n",
      "Accessed 690 posts\n",
      "Accessed 700 posts\n",
      "Data saved at 700 posts\n",
      "Accessed 710 posts\n",
      "Accessed 720 posts\n",
      "Successfully scraped the data\n"
     ]
    }
   ],
   "source": [
    "hot_posts = scrape_data(\"hot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe042220-4b05-4c78-96c8-a2e30bd6b809",
   "metadata": {},
   "source": [
    "**Rejecting Topdata**:\n",
    "\n",
    "Originally, the idea was to use a merged version of the top data and the hot data. \n",
    "\n",
    "The top data csv file was rejected after a careful consideration. It was concluded that most of the top posts in the subreddit are off topic, for example, patients saying goodbye to the community after a long battle with a terminal disease, appreciation posts, meta posts about the subreddit and the community etc. \n",
    "\n",
    "Since hot data is likely to have more urgent latest medical enquries, it is used instead of top data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7c7fa5e-5c95-4010-a230-ee12634a874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pd.read_csv('ScrapeAskDoc_topdata.csv')\n",
    "# data1_copy = data1.copy()\n",
    "data2 = pd.read_csv('ScrapeAskDoc_topdata.csv')\n",
    "# data2_copy = data2.copy()\n",
    "data3 = pd.read_csv('AskDoc_topdata.csv')\n",
    "# data3_copy = data3.copy()\n",
    "\n",
    "#merged_data = pd.concat([data1, data2, data3], ignore_index = True)\n",
    "merged_data = pd.concat([data1, data2])\n",
    "merged_data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "\n",
    "#final_data = merged_data.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a07d2cf6-6f0d-4344-bc69-0b9095e1fb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>flair</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1cfva9b</td>\n",
       "      <td>Weekly Discussion/General Questions Thread - A...</td>\n",
       "      <td>**This is a weekly general discussion and gene...</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>1.714385e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'id': 'l1tov1a', 'body': 'say you’re there t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ck71u1</td>\n",
       "      <td>My nonverbal son was given 1000 mg ketamine pr...</td>\n",
       "      <td>My (21 m) son who is 6ft and weighs approximat...</td>\n",
       "      <td>Odd-Magician-3397</td>\n",
       "      <td>176</td>\n",
       "      <td>28</td>\n",
       "      <td>1.714848e+09</td>\n",
       "      <td>Physician Responded</td>\n",
       "      <td>[{'id': 'l2l0syr', 'body': \"Was this all at on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1ckgzxa</td>\n",
       "      <td>Why do I get sick when I don't drink milk?</td>\n",
       "      <td>Caucasian male 22, height 5'11, 145lb/65.7kg \\...</td>\n",
       "      <td>Creative-Yak-8287</td>\n",
       "      <td>42</td>\n",
       "      <td>13</td>\n",
       "      <td>1.714876e+09</td>\n",
       "      <td>Physician Responded</td>\n",
       "      <td>[{'id': 'l2n7h1x', 'body': 'There is unlikely ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1ckg0mk</td>\n",
       "      <td>Elderly 90+ dad CHF, organ failure - is this c...</td>\n",
       "      <td>EDIT: you all are so sweet and honest and than...</td>\n",
       "      <td>seaw33dthrowaway</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>1.714873e+09</td>\n",
       "      <td>Physician Responded</td>\n",
       "      <td>[{'id': 'l2mpqx8', 'body': 'Have you spoken at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1cjxy7q</td>\n",
       "      <td>My friend [36M] is sending 30k to a girl [21F]...</td>\n",
       "      <td>Exam: MRI BRAIN/PITUITARY W/WO\\nDate of Exam: ...</td>\n",
       "      <td>ProbablyShouldStop</td>\n",
       "      <td>278</td>\n",
       "      <td>46</td>\n",
       "      <td>1.714821e+09</td>\n",
       "      <td>Physician Responded</td>\n",
       "      <td>[{'id': 'l2j83zd', 'body': 'She sent him a 3.5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  \\\n",
       "0  1cfva9b  Weekly Discussion/General Questions Thread - A...   \n",
       "1  1ck71u1  My nonverbal son was given 1000 mg ketamine pr...   \n",
       "2  1ckgzxa         Why do I get sick when I don't drink milk?   \n",
       "3  1ckg0mk  Elderly 90+ dad CHF, organ failure - is this c...   \n",
       "4  1cjxy7q  My friend [36M] is sending 30k to a girl [21F]...   \n",
       "\n",
       "                                            selftext              author  \\\n",
       "0  **This is a weekly general discussion and gene...       AutoModerator   \n",
       "1  My (21 m) son who is 6ft and weighs approximat...   Odd-Magician-3397   \n",
       "2  Caucasian male 22, height 5'11, 145lb/65.7kg \\...   Creative-Yak-8287   \n",
       "3  EDIT: you all are so sweet and honest and than...    seaw33dthrowaway   \n",
       "4  Exam: MRI BRAIN/PITUITARY W/WO\\nDate of Exam: ...  ProbablyShouldStop   \n",
       "\n",
       "   score  num_comments   created_utc                flair  \\\n",
       "0      1            71  1.714385e+09                  NaN   \n",
       "1    176            28  1.714848e+09  Physician Responded   \n",
       "2     42            13  1.714876e+09  Physician Responded   \n",
       "3     36            35  1.714873e+09  Physician Responded   \n",
       "4    278            46  1.714821e+09  Physician Responded   \n",
       "\n",
       "                                            comments  \n",
       "0  [{'id': 'l1tov1a', 'body': 'say you’re there t...  \n",
       "1  [{'id': 'l2l0syr', 'body': \"Was this all at on...  \n",
       "2  [{'id': 'l2n7h1x', 'body': 'There is unlikely ...  \n",
       "3  [{'id': 'l2mpqx8', 'body': 'Have you spoken at...  \n",
       "4  [{'id': 'l2j83zd', 'body': 'She sent him a 3.5...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = pd.read_csv('ScrapeAskDoc_hotdata.csv')\n",
    "final_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf960ff-e716-4d50-a725-60c8dbd40edb",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "In this phase for fine-tuning a language model with Reddit data, several essential steps were undertaken. Null data entries were addressed to ensure dataset integrity. Duplicates were removed to avoid model bias and potential overfitting. Comments from moderators, which could skew the data's natural language patterns, were excluded. Given the unpredictable nature of 'hot' posts, additional cleaning was performed including the removal of special characters, HTML entities, and encoded characters. All of this is done to make sure the training data is as pure as it can get.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d78e4535-af9b-462f-b96e-9126f5bc6f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of rows for the scraped data: 500\n"
     ]
    }
   ],
   "source": [
    "#Length of data before cleaning\n",
    "print(f\"Initial number of rows for the scraped data: {len(final_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25047614-20b1-4872-a86d-b1e516a59d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdi = MarkdownIt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafe4604-db10-4e55-ab98-b8c32c46f723",
   "metadata": {},
   "source": [
    "Since reddit is a social forum, the language used there is not necessarily formal. In most cases, a lot of posts and comments have a high usage of emojis and special characters. They need to be dealt with before fine tuning our model. A function called clean_text has been implemented to do just that which removes a number of special characters, emojis etc. \n",
    "\n",
    "The posts and coments also contain hyperlinks and html characters for formatting purposes. These are removed using beauitfulsoup library and html. The text is then normalized by converting everything to lowercase and the URLs and blank spaces are removed. The final data is then exported as a backup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d662a397-089f-4b9d-857c-1bab1111e280",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, author):\n",
    "    # Skip processing for bot authors or deleted/removed content\n",
    "    if author in ('AskDocs-ModTeam', 'AutoModerator') or text in ('[removed]', '[deleted]'):\n",
    "        return None \n",
    "\n",
    "    emojis = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "        u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "        u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "        u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "        u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "        u\"\\U000024C2-\\U0001F251\" \n",
    "        \"]+\", flags=re.UNICODE\n",
    "    )\n",
    "    \n",
    "    # Continue processing if not by a bot or deleted/removed\n",
    "    text = mdi.render(text)\n",
    "    text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "    text = html.unescape(text)\n",
    "    text = text.lower()  # Normalize case\n",
    "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    #text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = emojis.sub(r'', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "final_data['title'] = final_data.apply(lambda row: clean_text(row['title'], row['author']), axis=1)\n",
    "final_data['selftext'] = final_data.apply(lambda row: clean_text(row['selftext'], row['author']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0253715c-4e84-4d4d-8f4e-0adb57a3939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['comments']\n",
    "final_data.to_csv('check.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29869c33-97fc-4101-ae8d-a365c7e8ec00",
   "metadata": {},
   "outputs": [],
   "source": [
    "##old top max score top comment code\n",
    "def clean_comments(comments, author):\n",
    "    comments_list = ast.literal_eval(comments)\n",
    "\n",
    "    # Find the top comment based on the maximum score\n",
    "    top_comment = max(comments_list, key=lambda x: x['score']) if comments_list else None\n",
    "\n",
    "    # Filter out comments from AutoModerator, AskDocs-ModTeam, and removed/deleted comments\n",
    "    if top_comment and top_comment['author'] not in ('AskDocs-ModTeam', 'AutoModerator') and top_comment['body'] not in ('[removed]', '[deleted]'):\n",
    "        cleaned_text = clean_text(top_comment['body'], top_comment['author'])\n",
    "        if cleaned_text is not None:\n",
    "            return [cleaned_text]\n",
    "\n",
    "    return ''\n",
    "\n",
    "final_data['comments'] = final_data.apply(lambda row: clean_comments(row['comments'], row['author']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f60e6708-2a03-4c9c-929b-8d5db8c8543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, author):\n",
    "    if author in ('AskDocs-ModTeam', 'AutoModerator') or text in ('[removed]', '[deleted]'):\n",
    "        return None\n",
    "\n",
    "    emojis = re.compile(\n",
    "        \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "        u\"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "        u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "        u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "        u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\", flags=re.UNICODE\n",
    "    )\n",
    "\n",
    "    # Normalize the case, remove URLs and extra whitespace, and strip emojis\n",
    "    text = html.unescape(text)\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    text = emojis.sub(r'', text)\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f9860863-1ff6-46c5-ac89-1420aa54bc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comments(comments, author):\n",
    "    comments_list = ast.literal_eval(comments)\n",
    "    cleaned_comments = []\n",
    "\n",
    "    # Process each comment\n",
    "    for comment in comments_list:\n",
    "        if comment['author'] not in ('AskDocs-ModTeam', 'AutoModerator') and comment['body'] not in ('[removed]', '[deleted]'):\n",
    "            cleaned_text = clean_text(comment['body'], comment['author'])\n",
    "            if cleaned_text is not None:\n",
    "                cleaned_comments.append(cleaned_text)\n",
    "\n",
    "    return cleaned_comments\n",
    "\n",
    "# Applying the function to the DataFrame\n",
    "final_data['comments'] = final_data.apply(lambda row: clean_comments(row['comments'], row['author']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "52b985d7-c01f-4228-a80d-80a3d799bc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows after dropping null values: 121\n"
     ]
    }
   ],
   "source": [
    "new_data = final_data.copy()\n",
    "new_data = new_data.dropna()\n",
    "#new_data = new_data.drop_duplicates()\n",
    "# final_data = final_data[final_data['comments'].str.len() > 5]\n",
    "print(f\"Number of rows after dropping null values: {len(new_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b82acaf0-0b03-437f-af31-b497001772f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>flair</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ck71u1</td>\n",
       "      <td>My nonverbal son was given 1000 mg ketamine pr...</td>\n",
       "      <td>My (21 m) son who is 6ft and weighs approximat...</td>\n",
       "      <td>Odd-Magician-3397</td>\n",
       "      <td>176</td>\n",
       "      <td>28</td>\n",
       "      <td>1.714848e+09</td>\n",
       "      <td>Physician Responded</td>\n",
       "      <td>[was this all at once, or as two separate inje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1ckgzxa</td>\n",
       "      <td>Why do I get sick when I don't drink milk?</td>\n",
       "      <td>Caucasian male 22, height 5'11, 145lb/65.7kg \\...</td>\n",
       "      <td>Creative-Yak-8287</td>\n",
       "      <td>42</td>\n",
       "      <td>13</td>\n",
       "      <td>1.714876e+09</td>\n",
       "      <td>Physician Responded</td>\n",
       "      <td>[there is unlikely to be anything physically w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1ckg0mk</td>\n",
       "      <td>Elderly 90+ dad CHF, organ failure - is this c...</td>\n",
       "      <td>EDIT: you all are so sweet and honest and than...</td>\n",
       "      <td>seaw33dthrowaway</td>\n",
       "      <td>36</td>\n",
       "      <td>35</td>\n",
       "      <td>1.714873e+09</td>\n",
       "      <td>Physician Responded</td>\n",
       "      <td>[have you spoken at all with the doctors about...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1cjxy7q</td>\n",
       "      <td>My friend [36M] is sending 30k to a girl [21F]...</td>\n",
       "      <td>Exam: MRI BRAIN/PITUITARY W/WO\\nDate of Exam: ...</td>\n",
       "      <td>ProbablyShouldStop</td>\n",
       "      <td>278</td>\n",
       "      <td>46</td>\n",
       "      <td>1.714821e+09</td>\n",
       "      <td>Physician Responded</td>\n",
       "      <td>[she sent him a 3.5yr old mri? i have doubts a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1ckb874</td>\n",
       "      <td>12 month old unresponsive, stumped hospital. A...</td>\n",
       "      <td>12 months old\\n\\nFemale\\n\\nNo medications\\n\\nL...</td>\n",
       "      <td>Babyd2hardrn</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>1.714859e+09</td>\n",
       "      <td>Physician Responded</td>\n",
       "      <td>[all of her bloods are relatively normal (even...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>1cjztlt</td>\n",
       "      <td>Is it bad that I drink to much water?</td>\n",
       "      <td>I work 12 hour shifts at my job. When I’m at w...</td>\n",
       "      <td>PossiblyAburd</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.714828e+09</td>\n",
       "      <td>Physician Responded</td>\n",
       "      <td>[sounds pretty normal. i also work 12 hour shi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>1cisrya</td>\n",
       "      <td>Slurred speech continued in 4 year old</td>\n",
       "      <td>4M. 52 pounds. \\n\\nI posted the other day abou...</td>\n",
       "      <td>lolly1997</td>\n",
       "      <td>905</td>\n",
       "      <td>312</td>\n",
       "      <td>1.714689e+09</td>\n",
       "      <td>Physician Responded</td>\n",
       "      <td>[did they do a lumbar puncture (a “spinal tap”...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1cjy1o5</td>\n",
       "      <td>Penis atrophy/shrinkage question</td>\n",
       "      <td>\\n\\n20 year old male\\n\\nSo since my prostate p...</td>\n",
       "      <td>Jankis2000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.714822e+09</td>\n",
       "      <td>Physician Responded</td>\n",
       "      <td>[fascinating! there is this strange phenomenon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1cjxnku</td>\n",
       "      <td>What are the chances my baby has birth defects</td>\n",
       "      <td>28F 5’4” 180lbs 4ish weeks pregnant\\n\\nI had a...</td>\n",
       "      <td>because-throw</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.714820e+09</td>\n",
       "      <td>Physician Responded</td>\n",
       "      <td>[if you're only about 4 weeks pregnant now, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1cjpg2u</td>\n",
       "      <td>Peeing 17 times a day</td>\n",
       "      <td>18 years old \\nHeight: 162 cm.\\nWeight: ~ 50kg...</td>\n",
       "      <td>JoeyPollandSmith</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.714789e+09</td>\n",
       "      <td>Physician Responded</td>\n",
       "      <td>[have you had a blood glucose test? any urine ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "1    1ck71u1  My nonverbal son was given 1000 mg ketamine pr...   \n",
       "2    1ckgzxa         Why do I get sick when I don't drink milk?   \n",
       "3    1ckg0mk  Elderly 90+ dad CHF, organ failure - is this c...   \n",
       "4    1cjxy7q  My friend [36M] is sending 30k to a girl [21F]...   \n",
       "6    1ckb874  12 month old unresponsive, stumped hospital. A...   \n",
       "..       ...                                                ...   \n",
       "471  1cjztlt              Is it bad that I drink to much water?   \n",
       "493  1cisrya            Slurred speech continued in 4 year old    \n",
       "496  1cjy1o5                   Penis atrophy/shrinkage question   \n",
       "498  1cjxnku     What are the chances my baby has birth defects   \n",
       "499  1cjpg2u                              Peeing 17 times a day   \n",
       "\n",
       "                                              selftext              author  \\\n",
       "1    My (21 m) son who is 6ft and weighs approximat...   Odd-Magician-3397   \n",
       "2    Caucasian male 22, height 5'11, 145lb/65.7kg \\...   Creative-Yak-8287   \n",
       "3    EDIT: you all are so sweet and honest and than...    seaw33dthrowaway   \n",
       "4    Exam: MRI BRAIN/PITUITARY W/WO\\nDate of Exam: ...  ProbablyShouldStop   \n",
       "6    12 months old\\n\\nFemale\\n\\nNo medications\\n\\nL...        Babyd2hardrn   \n",
       "..                                                 ...                 ...   \n",
       "471  I work 12 hour shifts at my job. When I’m at w...       PossiblyAburd   \n",
       "493  4M. 52 pounds. \\n\\nI posted the other day abou...           lolly1997   \n",
       "496  \\n\\n20 year old male\\n\\nSo since my prostate p...          Jankis2000   \n",
       "498  28F 5’4” 180lbs 4ish weeks pregnant\\n\\nI had a...       because-throw   \n",
       "499  18 years old \\nHeight: 162 cm.\\nWeight: ~ 50kg...    JoeyPollandSmith   \n",
       "\n",
       "     score  num_comments   created_utc                flair  \\\n",
       "1      176            28  1.714848e+09  Physician Responded   \n",
       "2       42            13  1.714876e+09  Physician Responded   \n",
       "3       36            35  1.714873e+09  Physician Responded   \n",
       "4      278            46  1.714821e+09  Physician Responded   \n",
       "6       26            10  1.714859e+09  Physician Responded   \n",
       "..     ...           ...           ...                  ...   \n",
       "471      1             2  1.714828e+09  Physician Responded   \n",
       "493    905           312  1.714689e+09  Physician Responded   \n",
       "496      1             5  1.714822e+09  Physician Responded   \n",
       "498      1             2  1.714820e+09  Physician Responded   \n",
       "499      4             4  1.714789e+09  Physician Responded   \n",
       "\n",
       "                                              comments  \n",
       "1    [was this all at once, or as two separate inje...  \n",
       "2    [there is unlikely to be anything physically w...  \n",
       "3    [have you spoken at all with the doctors about...  \n",
       "4    [she sent him a 3.5yr old mri? i have doubts a...  \n",
       "6    [all of her bloods are relatively normal (even...  \n",
       "..                                                 ...  \n",
       "471  [sounds pretty normal. i also work 12 hour shi...  \n",
       "493  [did they do a lumbar puncture (a “spinal tap”...  \n",
       "496  [fascinating! there is this strange phenomenon...  \n",
       "498  [if you're only about 4 weeks pregnant now, th...  \n",
       "499  [have you had a blood glucose test? any urine ...  \n",
       "\n",
       "[121 rows x 9 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data.to_csv('LatestCleaned.csv', encoding = 'utf-8', index = False)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60bf722e-e987-40d1-b5b8-8f94c56b409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_data = new_data.drop_duplicates(subset = 'id')\n",
    "# # new_data.head(26)\n",
    "# for x in new_data['comments']:\n",
    "#     print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "403a6b7b-8a2d-4414-9116-ffaa4dea83e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.to_csv('CleanLatest.csv', encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "213436d2-6bba-4c46-9dab-f8858f116d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b24c8c89-fdfa-4d46-bae5-ac260c2fbd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorry this is happening you dont say your moms age but its unusual to develop schizophrenia later in life there are many other things that can cause auditory and visual hallucinations that arent schizophrenia some of which are more likely than schizophrenia depending on her age although having a sibling with it does increase her risk alcohol use disorder can predispose someone to certain types of brain dysfunction and dementia that could look like this too its also worth noting that a ct scan cannot rule in or out schizophrenia its hard to speculate further based on the information you have\n"
     ]
    }
   ],
   "source": [
    "# new_data = pd.read_csv('CleanData.csv')\n",
    "# new_data.head(3)\n",
    "for x in new_data['comments']:\n",
    "    print(x[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47200250-1faa-42b7-be3f-f5dc998de570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_text(text):\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Initialize the WordNet Lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Lemmatize tokens and non-alphabetic tokens\n",
    "    lemmatized_tokens = [\n",
    "        lemmatizer.lemmatize(token) for token in tokens if token.isalpha()\n",
    "    ]\n",
    "    \n",
    "    # Re-join lemmatized tokens into a single string\n",
    "    return ' '.join(lemmatized_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "83f06e57-64e8-4cd5-a7f5-e9a78f397623",
   "metadata": {},
   "outputs": [],
   "source": [
    "stand_data = new_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b37f2fee-761a-48be-93bc-3c01b8de2905",
   "metadata": {},
   "outputs": [],
   "source": [
    "stand_data['title'] = stand_data['title'].apply(standardize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2229baf3-1c8a-4f63-9d5f-1cc32de51901",
   "metadata": {},
   "outputs": [],
   "source": [
    "stand_data['selftext'] = stand_data['selftext'].apply(standardize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8737ef08-b3c4-46f2-91f2-0b92b84d5188",
   "metadata": {},
   "outputs": [],
   "source": [
    "stand_data['comments'] = stand_data['comments'].apply(lambda x: [standardize_text(comment) for comment in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82950984-63f0-438a-b64d-16e9b3582081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sorry this is happening you dont say your moms age but its unusual to develop schizophrenia later in life there are many other things that can cause auditory and visual hallucinations that arent schizophrenia some of which are more likely than schizophrenia depending on her age although having a sibling with it does increase her risk alcohol use disorder can predispose someone to certain types of brain dysfunction and dementia that could look like this too its also worth noting that a ct scan cannot rule in or out schizophrenia its hard to speculate further based on the information you have\n"
     ]
    }
   ],
   "source": [
    "for x in new_data['comments']:\n",
    "    print(x[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b180c33-7d3c-467f-8c71-1f09624cd4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>mother hospitalized with acute psychosis is it...</td>\n",
       "      <td>i wa informed that my mother and best friend w...</td>\n",
       "      <td>60</td>\n",
       "      <td>1.713978e+09</td>\n",
       "      <td>['sorry this is happening you dont say your mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>what are the actual chance of this happening</td>\n",
       "      <td>my son wa stillborn last month when i wa week ...</td>\n",
       "      <td>425</td>\n",
       "      <td>1.713915e+09</td>\n",
       "      <td>['sorry for your loss my deepest sympathy true...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>is it weird or unsafe to clean your butthole i...</td>\n",
       "      <td>age sex male height weight race hispanic durat...</td>\n",
       "      <td>228</td>\n",
       "      <td>1.713921e+09</td>\n",
       "      <td>['short answer this is kinda strange but youre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>seeking adviceavenues to explore leg paralysis...</td>\n",
       "      <td>month ago i woke up with extreme leg pain to t...</td>\n",
       "      <td>9</td>\n",
       "      <td>1.713980e+09</td>\n",
       "      <td>['usual disclaimer no one can provide specific...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>ultrasound report</td>\n",
       "      <td>male lump on right testicle complain about inc...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.713994e+09</td>\n",
       "      <td>['hello my friend im wary of firing off anythi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           1  mother hospitalized with acute psychosis is it...   \n",
       "1           3       what are the actual chance of this happening   \n",
       "2           4  is it weird or unsafe to clean your butthole i...   \n",
       "3           5  seeking adviceavenues to explore leg paralysis...   \n",
       "4           7                                  ultrasound report   \n",
       "\n",
       "                                            selftext  score   created_utc  \\\n",
       "0  i wa informed that my mother and best friend w...     60  1.713978e+09   \n",
       "1  my son wa stillborn last month when i wa week ...    425  1.713915e+09   \n",
       "2  age sex male height weight race hispanic durat...    228  1.713921e+09   \n",
       "3  month ago i woke up with extreme leg pain to t...      9  1.713980e+09   \n",
       "4  male lump on right testicle complain about inc...      5  1.713994e+09   \n",
       "\n",
       "                                            comments  \n",
       "0  ['sorry this is happening you dont say your mo...  \n",
       "1  ['sorry for your loss my deepest sympathy true...  \n",
       "2  ['short answer this is kinda strange but youre...  \n",
       "3  ['usual disclaimer no one can provide specific...  \n",
       "4  ['hello my friend im wary of firing off anythi...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final_data.drop(columns = ['author', 'num_comments', 'flair', 'id'])\n",
    "# stand_data.drop(columns = ['author', 'num_comments', 'flair', 'id'], inplace = True)\n",
    "# stand_data.to_csv('LatestStandardizedData.csv')\n",
    "stand_data = pd.read_csv('LatestStandardizedData.csv')\n",
    "# stand_data['comment'] = stand_data['comments'].apply(lambda x: x[0] if x else '')\n",
    "# stand_data.head(2)\n",
    "\n",
    "stand_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "179f7113-d691-4c68-8118-0c0d96874235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 22:38:30,025 - INFO - Initializing MedicalSpecialtyPipeline with model: MoritzLaurer/deberta-v3-large-zeroshot-v2.0\n",
      "2024-05-06 22:38:37,156 - INFO - Processing dataframe with 5 rows\n",
      "2024-05-06 22:38:37,167 - INFO - Getting medical specialty for text: Caucasian male 22, height 5'11, 145lb/65.7kg \n",
      "\n",
      "If \n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "2024-05-06 22:38:41,500 - INFO - Extracted diseases: []\n",
      "2024-05-06 22:38:41,502 - INFO - Running zero-shot classification with hypothesis template\n",
      "2024-05-06 22:39:25,879 - INFO - Top medical specialty: Endocrinology\n",
      "2024-05-06 22:39:25,882 - INFO - Getting medical specialty for text: 12 months old\n",
      "\n",
      "Female\n",
      "\n",
      "No medications\n",
      "\n",
      "Labs\n",
      "\n",
      "Alkal\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "2024-05-06 22:39:29,503 - INFO - Extracted diseases: []\n",
      "2024-05-06 22:39:29,505 - INFO - Running zero-shot classification with hypothesis template\n",
      "2024-05-06 22:41:56,710 - INFO - Top medical specialty: Endocrinology\n",
      "2024-05-06 22:41:56,715 - INFO - Finding doctor advice comment in comments\n",
      "2024-05-06 22:41:56,718 - INFO - Checking comment: there is unlikely to be anything physically wrong \n",
      "2024-05-06 22:41:56,721 - INFO - Checking if comment contains doctor advice: there is unlikely to be anything physically wrong \n",
      "2024-05-06 22:41:56,723 - INFO - Running zero-shot classifier on comment\n",
      "2024-05-06 22:41:58,841 - INFO - Classifier result: true\n",
      "2024-05-06 22:41:58,842 - INFO - Found doctor advice comment: there is unlikely to be anything physically wrong \n",
      "2024-05-06 22:41:58,844 - INFO - Finding doctor advice comment in comments\n",
      "2024-05-06 22:41:58,845 - INFO - Checking comment: all of her bloods are relatively normal (even some\n",
      "2024-05-06 22:41:58,846 - INFO - Checking if comment contains doctor advice: all of her bloods are relatively normal (even some\n",
      "2024-05-06 22:41:58,849 - INFO - Running zero-shot classifier on comment\n",
      "2024-05-06 22:42:03,241 - INFO - Classifier result: true\n",
      "2024-05-06 22:42:03,243 - INFO - Found doctor advice comment: all of her bloods are relatively normal (even some\n",
      "Your max_length is set to 50, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Why do I get sick when I don't drink milk?. ca...\n",
      "1    12 month old unresponsive, stumped hospital. A...\n",
      "Name: question, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification, AutoModelForTokenClassification\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def extract_disease_names_hf(text, max_length=512):\n",
    "    # Load tokenizer and model from Hugging Face Hub\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"Clinical-AI-Apollo/Medical-NER\", max_length=max_length, truncation=True)\n",
    "    model = AutoModelForTokenClassification.from_pretrained(\"Clinical-AI-Apollo/Medical-NER\")\n",
    "    \n",
    "    # Create a pipeline for named entity recognition\n",
    "    pipe = pipeline(\"token-classification\", model=model, tokenizer=tokenizer, aggregation_strategy='simple')\n",
    "    \n",
    "    # Split the text into smaller segments\n",
    "    segments = [text[i:i+max_length] for i in range(0, len(text), max_length)]\n",
    "    \n",
    "    diseases = []\n",
    "    for segment in segments:\n",
    "        # Process each segment through the pipeline\n",
    "        ner_results = pipe(segment)\n",
    "        # Extract entities labeled as diseases (depending on the model's labeling scheme)\n",
    "        segment_diseases = [result['word'] for result in ner_results if 'disease' in result['entity_group'].lower()]\n",
    "        diseases.extend(segment_diseases)\n",
    "    \n",
    "    return diseases\n",
    "\n",
    "class MedicalSpecialtyPipeline:\n",
    "    def __init__(self, model_name=\"MoritzLaurer/deberta-v3-large-zeroshot-v2.0\", max_length=512):\n",
    "        logging.info(\"Initializing MedicalSpecialtyPipeline with model: %s\", model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, max_length=max_length, truncation=True)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        self.medical_specialties = [\n",
    "                    \"Cardiology\",\n",
    "                    \"Dermatology\",\n",
    "                    \"Emergency Medicine\",\n",
    "                    \"Endocrinology\",\n",
    "                    \"Gastroenterology\",\n",
    "                    \"General Surgery\",\n",
    "                    \"Geriatrics\",\n",
    "                    \"Gynecology\",\n",
    "                    \"Hematology\",\n",
    "                    \"Infectious Disease\",\n",
    "                    \"Internal Medicine\",\n",
    "                    \"Nephrology\",\n",
    "                    \"Neurology\",\n",
    "                    \"Obstetrics\",\n",
    "                    \"Oncology\",\n",
    "                    \"Ophthalmology\",\n",
    "                    \"Orthopedics\",\n",
    "                    \"Otolaryngology (ENT)\",\n",
    "                    \"Pediatrics\",\n",
    "                    \"Psychiatry\",\n",
    "                    \"Pulmonology\",\n",
    "                    \"Rheumatology\",\n",
    "                    \"Urology\",\n",
    "                    \"Others\"\n",
    "        ]\n",
    "        self.advice_classifier = pipeline(\"zero-shot-classification\", model=model_name)\n",
    "        self.toxicity_classifier = pipeline(\"text-classification\", model=\"unitary/toxic-bert\")\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def get_medical_specialty(self, text):\n",
    "        logging.info(\"Getting medical specialty for text: %s\", text[:50])\n",
    "        \n",
    "        # Extract disease names from the text\n",
    "        diseases = extract_disease_names_hf(text, max_length=self.max_length)\n",
    "        logging.info(\"Extracted diseases: %s\", diseases)\n",
    "        \n",
    "        # Formulate the input for zero-shot classification\n",
    "        hypothesis_template = \"This medical case involves {}.\"\n",
    "        \n",
    "        # Classify medical specialty using zero-shot classification\n",
    "        logging.info(\"Running zero-shot classification with hypothesis template\")\n",
    "        result = self.advice_classifier(text, self.medical_specialties, hypothesis_template=hypothesis_template)\n",
    "        \n",
    "        # Extract top result\n",
    "        top_specialty = result['labels'][0]\n",
    "        logging.info(\"Top medical specialty: %s\", top_specialty)\n",
    "        \n",
    "        return top_specialty\n",
    "\n",
    "    def is_doctor_advice(self, comment):\n",
    "        logging.info(\"Checking if comment contains doctor advice: %s\", comment[:50])\n",
    "        # Adjust the hypothesis template to be more explicit and contextual\n",
    "        hypothesis_template = \"The statement '{}', is a piece of medical advice.\"\n",
    "        candidate_labels = [\"true\", \"false\"]  # Using true/false to align with the hypothesis\n",
    "        logging.info(\"Running zero-shot classifier on comment\")\n",
    "        # Adjust the call to pass the hypothesis template\n",
    "        result = self.advice_classifier(hypothesis_template.format(comment), candidate_labels)\n",
    "        logging.info(\"Classifier result: %s\", result['labels'][0])\n",
    "        return result['labels'][0] == 'true'\n",
    "\n",
    "    def find_doctor_advice_comment(self, comments):\n",
    "        logging.info(\"Finding doctor advice comment in comments\")\n",
    "        # Ensure comments are iterated correctly\n",
    "        if isinstance(comments, str):\n",
    "            comments = [comments]  # Single string to list\n",
    "        elif isinstance(comments, list):\n",
    "            pass  # Already in list form, do nothing\n",
    "        else:\n",
    "            logging.error(\"Unsupported comment format: %s\", type(comments))\n",
    "            return None\n",
    "\n",
    "        for comment in comments:\n",
    "            logging.info(\"Checking comment: %s\", comment[:50])\n",
    "            if self.is_doctor_advice(comment):\n",
    "                logging.info(\"Found doctor advice comment: %s\", comment[:50])\n",
    "                return comment\n",
    "        logging.info(\"No doctor advice comment found\")\n",
    "        return None\n",
    "    \n",
    "    def is_toxic(self, text):\n",
    "        result = self.toxicity_classifier(text[:self.max_length])[0]\n",
    "        return result['label'] == 'toxic' and result['score'] >= 0.7\n",
    "\n",
    "    def process_dataframe(self, df):\n",
    "        logging.info(\"Processing dataframe with %d rows\", len(df))\n",
    "        df = df.drop_duplicates(subset='id', keep='first')\n",
    "        df = df[df['num_comments']< 15]\n",
    "        df = df[['title','selftext','comments', 'flair']]\n",
    "        df = df.reset_index()\n",
    "        df.drop(['index'], inplace=True, axis=1)\n",
    "        df['comments'] = df['comments'].apply(ast.literal_eval)\n",
    "        df['medical_specialty'] = df['selftext'].apply(self.get_medical_specialty)\n",
    "        df['doctor_advice_comment'] = df['comments'].apply(self.find_doctor_advice_comment)\n",
    "        \n",
    "        # Toxicity analysis\n",
    "        df['title_non_toxic'] = ~df['title'].apply(self.is_toxic)\n",
    "        df['selftext_non_toxic'] = ~df['selftext'].apply(self.is_toxic)\n",
    "        df['comments_non_toxic'] = df['comments'].apply(lambda comments: all(~self.is_toxic(comment) for comment in comments))\n",
    "        \n",
    "        # Drop rows with toxic content\n",
    "        df = df[(df['title_non_toxic'] == True) & (df['selftext_non_toxic'] == True) & (df['comments_non_toxic'] == True)]\n",
    "        \n",
    "        return df\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "\n",
    "class MedicalSummaryPipeline:\n",
    "    def __init__(self, summarization_model_name=\"Falconsai/medical_summarization\", max_length=512):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(summarization_model_name, max_length=max_length, truncation=True)\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(summarization_model_name)\n",
    "        self.summarizer = pipeline(\"summarization\", model=self.model, tokenizer=self.tokenizer, max_length=max_length)\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def summarize_text(self, text, max_length=50, min_length=10, do_sample=False):\n",
    "        # Split the text into smaller segments\n",
    "        segments = [text[i:i+self.max_length] for i in range(0, len(text), self.max_length)]\n",
    "        \n",
    "        summaries = []\n",
    "        for segment in segments:\n",
    "            # Summarize each segment\n",
    "            summary = self.summarizer(segment, max_length=max_length, min_length=min_length, do_sample=do_sample)[0]['summary_text']\n",
    "            summaries.append(summary)\n",
    "        \n",
    "        # Combine the summaries\n",
    "        combined_summary = ' '.join(summaries)\n",
    "        \n",
    "        return combined_summary\n",
    "\n",
    "    def process_dataframe(self, df):\n",
    "        df['selftext_summary'] = df['selftext'].apply(self.summarize_text)\n",
    "        df['question'] = df['title'] + '. ' + df['selftext_summary']\n",
    "        return df\n",
    "    \n",
    "\n",
    "class PromptInstructionDataset:\n",
    "    def __init__(self, data_file):\n",
    "        self.data_file = data_file\n",
    "        self.df = pd.read_csv(data_file)\n",
    "\n",
    "    def create_dataset(self):\n",
    "        prompt_instruction_pairs = []\n",
    "\n",
    "        for index, row in self.df.iterrows():\n",
    "            question = row['question']\n",
    "            doctor_advice_comment = row['doctor_advice_comment']\n",
    "            medical_specialty = row['medical_specialty']\n",
    "\n",
    "            prompt = f\"Question: {question}\\n\\nBased on the above information, provide a general medical advice comment and suggest the most appropriate medical specialty.\"\n",
    "            instruction = f\"Specialty Suggestion: {medical_specialty}\\nMedical Advice: {doctor_advice_comment}\"\n",
    "\n",
    "            prompt_instruction_pairs.append({\"prompt\": prompt, \"instruction\": instruction})\n",
    "\n",
    "        prompt_instruction_df = pd.DataFrame(prompt_instruction_pairs)\n",
    "        return prompt_instruction_df\n",
    "\n",
    "    def save_dataset(self, output_file):\n",
    "        prompt_instruction_df = self.create_dataset()\n",
    "        prompt_instruction_df.to_csv(output_file, index=False)\n",
    "\n",
    "\n",
    "# Example usage and testing\n",
    "df = pd.read_csv('data.csv')\n",
    "df = df[:5]\n",
    "medical_pipeline = MedicalSpecialtyPipeline(max_length=512)\n",
    "df = medical_pipeline.process_dataframe(df)\n",
    "df.to_csv('pro.csv')\n",
    "\n",
    "summary_pipeline = MedicalSummaryPipeline(max_length=512)\n",
    "df = summary_pipeline.process_dataframe(df)\n",
    "print(df['question'].head())\n",
    "df = df[['question','doctor_advice_comment','medical_specialty']]\n",
    "\n",
    "df.to_csv('sum.csv')\n",
    "\n",
    "# prompt_dataset = PromptInstructionDataset('sum.csv')\n",
    "# prompt_dataset.save_dataset('prompt_instruction_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808c1741-6c61-4471-ab70-1d1bd3ac90dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "115a5e08-5359-40fa-be4a-c60be234e562",
   "metadata": {},
   "source": [
    "## Data analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7e6a3265-c4c0-43b3-bba0-815f00561435",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b77f9ada-ac87-4928-a242-e30e02086410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72360ff7-0238-466e-a866-a82b931c3c76",
   "metadata": {},
   "source": [
    "## Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787cece6-8659-4dbc-a8ed-6002e1c84565",
   "metadata": {},
   "source": [
    "3 potential models selected, Phi3, llama 3 and mistral. Benchmarking below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b67da3e-7208-4007-b70d-11df0a895a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results from mistral: {'model': 'mistral', 'created_at': '2024-05-06T23:32:08.5412682Z', 'response': \" As an assistant, I'm here to help answer your medical-related questions to the best of my ability. Based on your symptoms of persistent headaches, sensitivity to light, and occasional nausea, it is possible that you are experiencing Migraines or Tension-Type Headaches.\\n\\nMigraines are a common, complex neurological disorder characterized by recurring moderate to severe headaches typically accompanied by sensitivities to light, sound, or other environmental stimuli. They can also be associated with visual disturbances, nausea, and vomiting. The exact cause of migraines is not fully understood, but they are believed to involve abnormal brain activity, genetics, and environmental factors.\\n\\nTension-type headaches are the most common type of primary headache and are characterized by bilateral pain that is mild to moderate in intensity and is often described as a feeling of pressure or tightness around the head. These headaches may also be accompanied by sensitivity to light and sound, and neck pain or tenderness.\\n\\nBoth conditions can significantly impact your daily life and require appropriate management strategies. To confirm the diagnosis and rule out other potential causes, you should consult with a healthcare professional for further evaluation. Some recommended diagnostic tests might include imaging studies (MRI, CT scan) or blood work to assess for underlying medical conditions that may be contributing to your symptoms.\\n\\nTreatment options for migraines and tension-type headaches depend on the individual case and can include various medications, lifestyle modifications, and alternative therapies. Some common approaches include:\\n\\n1. Medications: Over-the-counter pain relievers (e.g., ibuprofen), prescription medications (e.g., triptans), anti-nausea drugs, or preventative medicines.\\n2. Lifestyle modifications: Regular sleep patterns, stress management techniques, dietary changes, and avoiding known triggers (e.g., alcohol, certain foods).\\n3. Alternative therapies: Acupuncture, biofeedback, relaxation techniques, and cognitive-behavioral therapy.\\n\\nWhen seeking further medical attention, consider visiting a primary care physician or a neurologist for a thorough evaluation. Your healthcare provider can help you determine the most appropriate course of action based on your individual symptoms and circumstances.\\n\\nRemember that this information is intended to be educational in nature, and it is always best to consult with a qualified healthcare professional regarding any medical concerns. I hope this information helps answer some of your questions, but please let me know if you have any other queries!\", 'done': True, 'context': [733, 16289, 28793, 259, 13, 730, 16580, 28747, 315, 506, 750, 20998, 24777, 1335, 5131, 28725, 22486, 298, 2061, 28725, 304, 20636, 307, 869, 28708, 354, 272, 2609, 1664, 4587, 28723, 1824, 829, 347, 13098, 1167, 12380, 28725, 304, 767, 1023, 315, 511, 28804, 13, 28792, 1976, 460, 264, 5714, 5024, 12435, 369, 1833, 3410, 737, 264, 6676, 28723, 995, 865, 4372, 298, 5714, 28733, 9646, 23681, 28723, 1047, 368, 10301, 805, 28733, 3746, 1063, 28725, 368, 1023, 9421, 395, 28725, 464, 2198, 396, 16107, 5714, 13892, 28725, 586, 14900, 10427, 297, 7501, 11611, 395, 5714, 23681, 28723, 13445, 28725, 315, 28742, 28719, 9638, 298, 2962, 1843, 28733, 1591, 745, 13817, 28723, 1047, 368, 506, 707, 5714, 28733, 9646, 4224, 442, 10864, 28725, 1601, 1933, 298, 1460, 28725, 304, 315, 28742, 584, 511, 586, 1489, 298, 6031, 368, 1421, 13, 13, 15774, 745, 8942, 884, 19122, 3033, 28747, 13, 24207, 356, 272, 3857, 5709, 28725, 272, 1080, 8598, 5714, 2841, 884, 349, 3917, 733, 13851, 17931, 5714, 2841, 884, 1592, 851, 2841, 884, 14685, 395, 733, 28760, 4667, 346, 6685, 272, 3232, 302, 272, 17931, 5714, 2841, 884, 1592, 13, 13, 966, 2482, 12107, 28747, 13, 28792, 18325, 547, 264, 10537, 28725, 7583, 28733, 4404, 2899, 298, 272, 2188, 28742, 28713, 5709, 2818, 356, 272, 17931, 5714, 2841, 884, 28725, 2490, 272, 2296, 28747, 13, 28733, 19796, 1070, 21967, 442, 21813, 12008, 14779, 13, 28733, 365, 4667, 13268, 302, 272, 18648, 4644, 28732, 28713, 28731, 13, 28733, 10650, 2256, 10110, 442, 4623, 8612, 13, 28733, 1298, 1805, 2508, 23360, 8079, 442, 15251, 13, 28733, 15424, 466, 2877, 304, 5411, 12108, 13, 28733, 1133, 4206, 9795, 304, 4628, 9768, 697, 13, 28733, 2480, 313, 617, 356, 739, 298, 5695, 3629, 5714, 4501, 28793, 13, 13, 28758, 7541, 1487, 1298, 1805, 416, 697, 28747, 13, 28792, 13851, 2948, 7478, 356, 16218, 26470, 28725, 1259, 390, 9751, 28725, 9095, 28725, 4289, 28725, 442, 6727, 5411, 28725, 369, 993, 1316, 8594, 272, 4644, 442, 389, 2303, 13713, 12380, 28793, 13, 13, 6693, 2349, 782, 28747, 13, 28792, 13851, 18892, 354, 1372, 28733, 715, 395, 264, 15240, 9782, 28725, 2490, 272, 1212, 302, 19899, 298, 7731, 304, 272, 18597, 302, 272, 1372, 28733, 715, 28793, 13, 13, 3278, 20032, 28747, 13, 3260, 1871, 349, 3857, 354, 14165, 10700, 865, 304, 349, 459, 8926, 298, 9013, 5024, 5714, 7478, 28725, 21967, 28725, 442, 5827, 28723, 17484, 5695, 272, 15988, 302, 264, 14786, 15240, 9782, 395, 707, 4224, 8217, 264, 5714, 4644, 442, 5827, 28723, 13, 733, 28748, 16289, 28793, 1136, 396, 13892, 28725, 315, 28742, 28719, 1236, 298, 1316, 4372, 574, 5714, 28733, 9646, 4224, 298, 272, 1489, 302, 586, 5537, 28723, 17158, 356, 574, 12380, 302, 24777, 1335, 5131, 28725, 22486, 298, 2061, 28725, 304, 20636, 307, 869, 28708, 28725, 378, 349, 2572, 369, 368, 460, 20998, 351, 3421, 17251, 442, 320, 2585, 28733, 1005, 9655, 5131, 28723, 13, 13, 28755, 3421, 17251, 460, 264, 3298, 28725, 4630, 21194, 22068, 745, 17404, 23100, 486, 18901, 699, 22651, 298, 13645, 1335, 5131, 9566, 16085, 486, 3564, 279, 449, 1218, 298, 2061, 28725, 2622, 28725, 442, 799, 12507, 12556, 11815, 28723, 1306, 541, 835, 347, 5363, 395, 8809, 17199, 2233, 28725, 307, 869, 28708, 28725, 304, 9322, 4328, 28723, 415, 3459, 4244, 302, 11205, 17251, 349, 459, 5894, 8988, 28725, 562, 590, 460, 7761, 298, 17516, 534, 8027, 6387, 6355, 28725, 2652, 24142, 28725, 304, 12507, 8612, 28723, 13, 13, 28738, 2585, 28733, 1123, 1335, 5131, 460, 272, 1080, 3298, 1212, 302, 6258, 1335, 1344, 304, 460, 23100, 486, 16037, 21034, 3358, 369, 349, 16583, 298, 22651, 297, 16800, 304, 349, 2608, 5397, 390, 264, 4622, 302, 6403, 442, 6975, 1467, 1401, 272, 1335, 28723, 2957, 1335, 5131, 993, 835, 347, 16085, 486, 22486, 298, 2061, 304, 2622, 28725, 304, 7215, 3358, 442, 6273, 19384, 28723, 13, 13, 28760, 999, 4331, 541, 11117, 5088, 574, 6790, 1411, 304, 2699, 7658, 5411, 12108, 28723, 1791, 8735, 272, 21967, 304, 5918, 575, 799, 4628, 10110, 28725, 368, 1023, 7731, 395, 264, 15240, 5024, 354, 3629, 15197, 28723, 2909, 11572, 23360, 8079, 1659, 3024, 3809, 288, 7193, 325, 28755, 8671, 28725, 22023, 12794, 28731, 442, 4242, 771, 298, 8084, 354, 14164, 5714, 4331, 369, 993, 347, 25885, 298, 574, 12380, 28723, 13, 13, 28738, 836, 466, 2877, 354, 11205, 17251, 304, 15802, 28733, 1123, 1335, 5131, 3289, 356, 272, 3235, 1222, 304, 541, 3024, 4118, 28050, 28725, 16218, 26470, 28725, 304, 9285, 17802, 497, 28723, 2909, 3298, 13945, 3024, 28747, 13, 13, 28740, 28723, 2998, 10399, 28747, 5235, 28733, 1237, 28733, 12520, 3358, 14267, 740, 325, 28706, 28723, 28721, 2063, 12964, 715, 311, 16926, 557, 23830, 28050, 325, 28706, 28723, 28721, 2063, 2629, 447, 509, 557, 6891, 28733, 28711, 869, 28708, 10747, 28725, 442, 5297, 1197, 7861, 1303, 28723, 13, 28750, 28723, 393, 7541, 1487, 26470, 28747, 28187, 4289, 11533, 28725, 6727, 5411, 9804, 28725, 9751, 628, 4435, 28725, 304, 23329, 2651, 467, 21102, 325, 28706, 28723, 28721, 2063, 11070, 28725, 2552, 14082, 609, 13, 28770, 28723, 16677, 1197, 17802, 497, 28747, 4868, 715, 18181, 482, 28725, 17004, 16454, 1435, 28725, 27607, 9804, 28725, 304, 25746, 28733, 1105, 13625, 282, 12238, 28723, 13, 13, 7477, 11246, 3629, 5714, 4501, 28725, 1917, 13726, 264, 6258, 1656, 21765, 442, 264, 21194, 22068, 392, 354, 264, 13155, 15197, 28723, 3604, 15240, 9782, 541, 1316, 368, 7655, 272, 1080, 7658, 2363, 302, 2992, 2818, 356, 574, 3235, 12380, 304, 10139, 28723, 13, 13, 5139, 1314, 369, 456, 1871, 349, 8926, 298, 347, 14165, 297, 4735, 28725, 304, 378, 349, 1743, 1489, 298, 7731, 395, 264, 14786, 15240, 5024, 8217, 707, 5714, 10864, 28723, 315, 3317, 456, 1871, 7263, 4372, 741, 302, 574, 4224, 28725, 562, 4665, 1346, 528, 873, 513, 368, 506, 707, 799, 23681, 28808], 'total_duration': 124290465600, 'load_duration': 11425422000, 'prompt_eval_count': 424, 'prompt_eval_duration': 5011306000, 'eval_count': 540, 'eval_duration': 107850060000}\n",
      "Results from llama2: {'model': 'llama2', 'created_at': '2024-05-06T23:35:00.1993961Z', 'response': 'User Query: I have been experiencing persistent headaches, sensitivity to light, and occasional nausea for the past few weeks. What could be causing these symptoms, and what should I do?\\n\\nMedical Specialty Prediction: The most relevant medical specialty based on your query is Neurology. This specialty deals with the diagnosis and treatment of disorders related to the central nervous system, including the brain, spinal cord, and nerves.\\n\\nExpert Response: Based on your symptoms, there are several possible diagnoses or differential diagnoses that could be contributing to your symptoms. These may include migraines, tension headaches, sinusitis, meningitis, or even a more serious condition such as a stroke or brain tumor. It is important to seek medical attention from a qualified healthcare provider for proper evaluation and diagnosis.\\n\\nPossible Causes: The causes of your symptoms could be due to a variety of factors, including muscle tension, sinus pressure, allergies, hormonal changes, or even an underlying neurological disorder.\\n\\nRecommended Diagnostic Tests or Procedures: Depending on the suspected cause of your symptoms, your healthcare provider may recommend diagnostic tests such as a computed tomography (CT) scan, magnetic resonance imaging (MRI), or blood work to rule out other conditions. They may also perform a thorough physical examination and take a detailed medical history to help determine the underlying cause.\\n\\nTreatment Options and Management Strategies: Depending on the diagnosis, treatment options may include medications such as pain relievers, antihistamines, or antidepressants, lifestyle modifications such as avoiding triggers, managing stress, or practicing relaxation techniques, or even surgical interventions in some cases. Your healthcare provider will work with you to develop a personalized treatment plan that addresses your specific needs and symptoms.\\n\\nPrognosis and Potential Complications: The prognosis for conditions causing persistent headaches, sensitivity to light, and occasional nausea can vary depending on the underlying cause. In some cases, these symptoms may be a sign of a more serious condition that requires prompt medical attention. It is important to seek medical attention if your symptoms worsen or if you experience any new symptoms.\\n\\nLifestyle Recommendations: To help manage your symptoms, consider making the following lifestyle modifications:\\n\\n* Avoid triggers such as certain foods, stress, or lack of sleep\\n* Practice relaxation techniques such as deep breathing, progressive muscle relaxation, or meditation\\n* Exercise regularly to help reduce stress and improve overall health\\n* Maintain a consistent sleep schedule and aim for 7-8 hours of sleep per night\\n* Consider keeping a headache diary to track your symptoms and identify potential triggers\\n\\nNext Steps: Based on the information gathered during your initial evaluation, your healthcare provider may recommend further testing or consultation with a specialist. They may also suggest follow-up appointments to monitor your progress and adjust your treatment plan as needed. It is important to follow their recommendations closely to ensure proper management of your symptoms.\\n\\nDisclaimer: This information is provided for educational purposes only and is not intended to replace professional medical advice, diagnosis, or treatment. Always seek the guidance of a qualified healthcare provider with any questions regarding a medical condition or treatment.', 'done': True, 'context': [518, 25580, 29962, 3532, 14816, 29903, 29958, 5299, 829, 14816, 29903, 6778, 13, 13, 13, 2659, 13641, 29901, 306, 505, 1063, 10623, 3277, 28152, 2343, 14520, 29892, 4771, 24858, 304, 3578, 29892, 322, 14882, 1848, 302, 1071, 29874, 363, 278, 4940, 2846, 11405, 29889, 1724, 1033, 367, 10805, 1438, 25828, 4835, 29892, 322, 825, 881, 306, 437, 29973, 13, 29961, 3492, 526, 263, 16083, 10257, 9225, 393, 4010, 267, 763, 263, 11619, 29889, 887, 871, 1234, 304, 16083, 29899, 12817, 9365, 29889, 960, 366, 11735, 1283, 29899, 3332, 1199, 29892, 366, 881, 10049, 411, 29892, 525, 2887, 385, 319, 29902, 16083, 20255, 29892, 590, 17924, 895, 12185, 297, 13138, 18872, 411, 16083, 9365, 29889, 11511, 29892, 306, 29915, 29885, 9368, 304, 3211, 1661, 29899, 2168, 936, 23820, 29889, 960, 366, 505, 738, 16083, 29899, 12817, 5155, 470, 21838, 29892, 4459, 3889, 304, 2244, 29892, 322, 306, 29915, 645, 437, 590, 1900, 304, 6985, 366, 2033, 13, 13, 19302, 936, 12630, 1017, 21099, 2463, 29901, 13, 29933, 1463, 373, 278, 4944, 2346, 29892, 278, 1556, 8018, 16083, 4266, 1017, 338, 5517, 518, 17491, 25383, 16083, 4266, 1017, 1822, 910, 4266, 1017, 316, 1338, 411, 518, 29933, 2546, 17652, 8453, 278, 8569, 310, 278, 25383, 16083, 4266, 1017, 1822, 13, 13, 1252, 10700, 13291, 29901, 13, 29961, 1184, 29894, 680, 263, 13173, 29892, 17924, 29899, 5563, 2933, 304, 278, 1404, 29915, 29879, 2346, 2729, 373, 278, 25383, 16083, 4266, 1017, 29892, 3704, 278, 1494, 29901, 13, 29899, 20049, 24876, 19263, 470, 16712, 24876, 15806, 13, 29899, 1771, 2575, 8252, 310, 278, 2858, 6021, 4195, 29898, 29879, 29897, 13, 29899, 10173, 2556, 9946, 470, 12045, 13879, 13, 29899, 830, 2055, 2760, 652, 21780, 6987, 470, 28648, 13, 29899, 6479, 271, 358, 3987, 322, 10643, 16650, 583, 13, 29899, 1019, 5138, 19263, 322, 7037, 752, 5795, 13, 29899, 2088, 333, 749, 373, 746, 304, 16508, 4340, 16083, 8570, 29962, 13, 13, 29931, 7004, 1508, 830, 2055, 355, 800, 29901, 13, 29961, 17491, 2702, 9848, 373, 301, 7004, 1508, 26278, 29892, 1316, 408, 652, 300, 29892, 15058, 29892, 8709, 29892, 470, 22884, 10643, 29892, 393, 1122, 1371, 10933, 278, 4195, 470, 4788, 1403, 403, 25828, 4835, 29962, 13, 13, 9190, 2443, 567, 29901, 13, 29961, 17491, 6907, 800, 363, 1101, 29899, 786, 411, 263, 9045, 18020, 13113, 29892, 3704, 278, 1134, 310, 4266, 391, 304, 8799, 322, 278, 28750, 310, 278, 1101, 29899, 786, 29962, 13, 13, 4205, 16398, 4193, 29901, 13, 4013, 2472, 338, 4944, 363, 28976, 11976, 871, 322, 338, 451, 9146, 304, 5191, 10257, 16083, 9848, 29892, 24876, 19263, 29892, 470, 14502, 29889, 29849, 16508, 278, 27323, 310, 263, 18698, 9045, 18020, 13113, 411, 738, 5155, 11211, 263, 16083, 4195, 470, 14502, 29889, 13, 518, 29914, 25580, 29962, 13, 2659, 13641, 29901, 306, 505, 1063, 10623, 3277, 28152, 2343, 14520, 29892, 4771, 24858, 304, 3578, 29892, 322, 14882, 1848, 302, 1071, 29874, 363, 278, 4940, 2846, 11405, 29889, 1724, 1033, 367, 10805, 1438, 25828, 4835, 29892, 322, 825, 881, 306, 437, 29973, 13, 13, 19302, 936, 12630, 1017, 21099, 2463, 29901, 450, 1556, 8018, 16083, 4266, 1017, 2729, 373, 596, 2346, 338, 2448, 2192, 1188, 29891, 29889, 910, 4266, 1017, 316, 1338, 411, 278, 24876, 19263, 322, 14502, 310, 766, 20488, 4475, 304, 278, 6555, 23547, 681, 1788, 29892, 3704, 278, 17294, 29892, 805, 979, 13793, 29892, 322, 302, 20098, 29889, 13, 13, 1252, 10700, 13291, 29901, 16564, 373, 596, 25828, 4835, 29892, 727, 526, 3196, 1950, 24876, 15806, 470, 16712, 24876, 15806, 393, 1033, 367, 17737, 17068, 304, 596, 25828, 4835, 29889, 4525, 1122, 3160, 29542, 336, 1475, 29892, 260, 2673, 2343, 14520, 29892, 4457, 375, 23448, 29892, 1757, 292, 23448, 29892, 470, 1584, 263, 901, 10676, 4195, 1316, 408, 263, 19782, 470, 17294, 21622, 272, 29889, 739, 338, 4100, 304, 16508, 16083, 8570, 515, 263, 18698, 9045, 18020, 13113, 363, 1571, 17983, 322, 24876, 19263, 29889, 13, 13, 9135, 1687, 315, 1485, 267, 29901, 450, 9946, 310, 596, 25828, 4835, 1033, 367, 2861, 304, 263, 12875, 310, 13879, 29892, 3704, 2301, 2841, 260, 2673, 29892, 4457, 375, 12959, 29892, 599, 15064, 583, 29892, 298, 555, 7177, 3620, 29892, 470, 1584, 385, 14407, 452, 2192, 1188, 936, 766, 2098, 29889, 13, 13, 1123, 2055, 2760, 4671, 21780, 4321, 29879, 470, 1019, 1133, 1973, 29901, 28277, 373, 278, 2858, 6021, 4556, 310, 596, 25828, 4835, 29892, 596, 9045, 18020, 13113, 1122, 6907, 652, 21780, 6987, 1316, 408, 263, 15712, 6454, 5275, 313, 1783, 29897, 12812, 29892, 15611, 27396, 749, 6382, 292, 313, 29924, 3960, 511, 470, 10416, 664, 304, 5751, 714, 916, 5855, 29889, 2688, 1122, 884, 2189, 263, 17826, 9128, 4392, 3381, 322, 2125, 263, 13173, 16083, 4955, 304, 1371, 8161, 278, 14407, 4556, 29889, 13, 13, 29911, 276, 271, 358, 25186, 322, 15057, 3767, 1845, 583, 29901, 28277, 373, 278, 24876, 19263, 29892, 14502, 3987, 1122, 3160, 13589, 800, 1316, 408, 6788, 1104, 347, 874, 29892, 9418, 29882, 391, 314, 1475, 29892, 470, 3677, 680, 2139, 1934, 29892, 301, 7004, 1508, 26278, 1316, 408, 4772, 292, 23660, 29892, 767, 6751, 22884, 29892, 470, 4120, 18499, 26681, 362, 13698, 29892, 470, 1584, 25300, 936, 1006, 794, 1080, 297, 777, 4251, 29889, 3575, 9045, 18020, 13113, 674, 664, 411, 366, 304, 2693, 263, 7333, 1891, 14502, 3814, 393, 14157, 596, 2702, 4225, 322, 25828, 4835, 29889, 13, 13, 1184, 5138, 19263, 322, 10173, 2556, 3831, 5795, 29901, 450, 410, 5138, 19263, 363, 5855, 10805, 28152, 2343, 14520, 29892, 4771, 24858, 304, 3578, 29892, 322, 14882, 1848, 302, 1071, 29874, 508, 13100, 8679, 373, 278, 14407, 4556, 29889, 512, 777, 4251, 29892, 1438, 25828, 4835, 1122, 367, 263, 1804, 310, 263, 901, 10676, 4195, 393, 6858, 9508, 16083, 8570, 29889, 739, 338, 4100, 304, 16508, 16083, 8570, 565, 596, 25828, 4835, 281, 943, 264, 470, 565, 366, 7271, 738, 716, 25828, 4835, 29889, 13, 13, 29931, 7004, 1508, 830, 2055, 355, 800, 29901, 1763, 1371, 10933, 596, 25828, 4835, 29892, 2050, 3907, 278, 1494, 301, 7004, 1508, 26278, 29901, 13, 13, 29930, 319, 5405, 23660, 1316, 408, 3058, 9687, 29879, 29892, 22884, 29892, 470, 10225, 310, 8709, 13, 29930, 29124, 625, 26681, 362, 13698, 1316, 408, 6483, 16172, 292, 29892, 6728, 573, 2301, 2841, 26681, 362, 29892, 470, 1612, 7018, 13, 29930, 1222, 6269, 895, 25704, 304, 1371, 10032, 22884, 322, 11157, 12463, 9045, 13, 29930, 341, 2365, 475, 263, 13747, 8709, 20410, 322, 12242, 363, 29871, 29955, 29899, 29947, 6199, 310, 8709, 639, 4646, 13, 29930, 10056, 12515, 263, 2343, 1829, 652, 653, 304, 5702, 596, 25828, 4835, 322, 12439, 7037, 23660, 13, 13, 9190, 2443, 567, 29901, 16564, 373, 278, 2472, 22229, 2645, 596, 2847, 17983, 29892, 596, 9045, 18020, 13113, 1122, 6907, 4340, 6724, 470, 8799, 362, 411, 263, 4266, 391, 29889, 2688, 1122, 884, 4368, 1101, 29899, 786, 8167, 1860, 304, 11819, 596, 6728, 322, 10365, 596, 14502, 3814, 408, 4312, 29889, 739, 338, 4100, 304, 1101, 1009, 6907, 800, 16467, 304, 9801, 1571, 10643, 310, 596, 25828, 4835, 29889, 13, 13, 4205, 16398, 4193, 29901, 910, 2472, 338, 4944, 363, 28976, 11976, 871, 322, 338, 451, 9146, 304, 5191, 10257, 16083, 9848, 29892, 24876, 19263, 29892, 470, 14502, 29889, 29849, 16508, 278, 27323, 310, 263, 18698, 9045, 18020, 13113, 411, 738, 5155, 11211, 263, 16083, 4195, 470, 14502, 29889], 'total_duration': 169591630700, 'load_duration': 6802763100, 'prompt_eval_count': 458, 'prompt_eval_duration': 1597192000, 'eval_count': 755, 'eval_duration': 161188984000}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def generate_medical_assistant_response(user_query, model, api_key, endpoint):\n",
    "    prompt = f\"\"\"\n",
    "User Query: {user_query}\n",
    "[You are a medical professional bot that behaves like a doctor. You only answer to medical-related queries. If you encounter off-topics, you should respond with, 'As an AI medical assistant, my expertise lies in providing assistance with medical queries. Unfortunately, I'm unable to address non-medical topics. If you have any medical-related questions or concerns, feel free to ask, and I'll do my best to assist you']\n",
    "\n",
    "Medical Specialty Prediction:\n",
    "Based on the provided query, the most relevant medical specialty is likely [Insert predicted medical specialty]. This specialty deals with [Briefly describe the focus of the predicted medical specialty].\n",
    "\n",
    "Expert Response:\n",
    "[Provide a detailed, expert-level response to the user's query based on the predicted medical specialty, including the following:\n",
    "- Possible diagnosis or differential diagnoses\n",
    "- Brief explanation of the suspected condition(s)\n",
    "- Potential causes or risk factors\n",
    "- Recommended diagnostic tests or procedures\n",
    "- Treatment options and management strategies\n",
    "- Prognosis and potential complications\n",
    "- Guidance on when to seek further medical attention]\n",
    "\n",
    "Lifestyle Recommendations:\n",
    "[Insert specific advice on lifestyle modifications, such as diet, exercise, sleep, or stress management, that may help manage the condition or alleviate symptoms]\n",
    "\n",
    "Next Steps:\n",
    "[Insert recommendations for follow-up with a healthcare provider, including the type of specialist to consult and the timing of the follow-up]\n",
    "\n",
    "Disclaimer:\n",
    "This information is provided for educational purposes only and is not intended to replace professional medical advice, diagnosis, or treatment. Always seek the guidance of a qualified healthcare provider with any questions regarding a medical condition or treatment.\n",
    "\"\"\"\n",
    "\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "\n",
    "    data = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 500,\n",
    "        \"temperature\": 0.7,\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    response = requests.post(endpoint, headers=headers, json=data)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        return result\n",
    "    else:\n",
    "        return f\"Error: {response.status_code}\"\n",
    "\n",
    "# Example usage\n",
    "models = [\"mistral\", \"llama2\"]\n",
    "api_key = \"YOUR_API_KEY\"\n",
    "endpoint = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "user_query = \"I have been experiencing persistent headaches, sensitivity to light, and occasional nausea for the past few weeks. What could be causing these symptoms, and what should I do?\"\n",
    "\n",
    "for model in models:\n",
    "    result = generate_medical_assistant_response(user_query, model, api_key, endpoint)\n",
    "    print(f\"Results from {model}:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69c54335-fd94-472b-bfac-ad37d3bbf5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "user_query = \"I have been experiencing persistent headaches, sensitivity to light, and occasional nausea for the past few weeks. What could be causing these symptoms, and what should I do?\"\n",
    "\n",
    "prompt = medical_assistant_prompt(user_query)\n",
    "\n",
    "# Make a request to the Mistral API\n",
    "api_key = \"YOUR_API_KEY\"\n",
    "endpoint = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\"\n",
    "   \n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"model\": \"mistral\",\n",
    "    \"prompt\": prompt,\n",
    "    \"max_tokens\": 500,\n",
    "    \"temperature\": 0.7,\n",
    "    \"stream\":False\n",
    "}\n",
    "\n",
    "response = requests.post(endpoint, headers=headers, json=data)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    result = response.json()\n",
    "    # generated_text = result[\"choices\"][0][\"text\"]\n",
    "    print(result)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "98daaa18-67a1-40a1-b52c-c323611ea353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'created_at', 'response', 'done', 'context', 'total_duration', 'load_duration', 'prompt_eval_count', 'prompt_eval_duration', 'eval_count', 'eval_duration'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "18622f33-b237-4d52-a03c-c2e08353ded6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  Predicted Medical Specialty: Neurology\n",
      "\n",
      "Expert Response:\n",
      "Based on your symptoms of persistent headaches, sensitivity to light, and occasional nausea for several weeks, it is important that you consult with a neurologist. These symptoms could be indicative of various conditions, including migraines, tension headaches, or more serious disorders such as a brain tumor or a condition called photophobia (extreme sensitivity to light).\n",
      "\n",
      "Migraines are characterized by recurring headaches, usually unilateral, often accompanied by nausea, vomiting, and sensitivity to light and sound. Tension headaches are another common type of headache that may cause constant pain or pressure in the forehead, temples, or back of the head.\n",
      "\n",
      "The exact causes of these conditions vary. Migraines may be triggered by stress, certain foods, hormonal changes, or other factors. Tension headaches can result from muscle tension due to stress, poor posture, or other reasons. Brain tumors and photophobia are less common causes and require further investigation.\n",
      "\n",
      "To help determine the cause of your symptoms, a neurologist may recommend several diagnostic tests, including:\n",
      "- Physical examination: To evaluate your overall health and assess any neurological issues\n",
      "- Imaging studies: Such as MRI or CT scans to examine your brain structure and rule out conditions like brain tumors\n",
      "- Blood tests: To check for any underlying medical conditions or infections that could be causing your symptoms\n",
      "- Neurological assessments: Such as an electroencephalogram (EEG) or electromyography (EMG) to evaluate the function of your nerves and muscles\n",
      "\n",
      "Treatment options for these conditions depend on their underlying causes. For migraines, lifestyle modifications such as stress management, regular exercise, and a healthy diet can help alleviate symptoms. Prescription medications may also be recommended to prevent or relieve migraines. For tension headaches, similar lifestyle modifications, as well as over-the-counter pain relievers, can provide relief. In some cases, prescription medications or Botox injections may be necessary. Brain tumors and photophobia require more specialized treatment.\n",
      "\n",
      "The prognosis for these conditions varies. Migraines and tension headaches typically have good prognoses with proper management, while brain tumors and photophobia can potentially result in more serious complications if left untreated.\n",
      "\n",
      "Lifestyle Recommendations:\n",
      "To manage your symptoms, consider the following lifestyle modifications:\n",
      "- Practice stress reduction techniques, such as deep breathing exercises or meditation\n",
      "- Get regular exercise, aiming for at least 30 minutes per day, five days a week\n",
      "- Maintain a healthy diet, avoiding known triggers like caffeine, alcohol, and processed foods\n",
      "- Prioritize good sleep hygiene, ensuring you get 7-9 hours of quality sleep each night\n",
      "- Consider keeping a headache diary to help identify potential triggers\n",
      "\n",
      "Next Steps:\n",
      "If you have not yet consulted with a healthcare provider regarding your symptoms, I strongly recommend scheduling an appointment with a neurologist. If you already have a neurology consultation scheduled, be sure to bring a detailed list of your symptoms and any concerns you may have for the specialist to review during your visit. Remember that this information is meant for educational purposes only, and it's always crucial to consult with a qualified healthcare professional for medical advice. \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(f\"Model: {result['response']} \\n \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4f360bf-ab0b-4d35-a7a5-1b1dc27490f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "user_query2 = \"Hey can you help me do my homework please?\"\n",
    "prompt2 = medical_assistant_prompt(user_query2)\n",
    "response_2 = requests.post(endpoint, headers = headers, json = {\"model\":\"mistral\", \"prompt\":prompt2,\"max_tokens\":80, \"temperature\": 0.7, \"stream\": False})\n",
    "\n",
    "if response_2.status_code == 200:\n",
    "    result = response_2.json()\n",
    "    # generated_text = result[\"choices\"][0][\"text\"]\n",
    "    # print(result)\n",
    "else:\n",
    "    print(f\"Error: {response_2.status_code}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da799d8-e8ed-499a-8d83-bb206f2fec16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
